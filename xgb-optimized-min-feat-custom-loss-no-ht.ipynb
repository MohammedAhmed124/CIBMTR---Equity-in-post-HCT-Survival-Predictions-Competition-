{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5c207e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:25.592545Z",
     "iopub.status.busy": "2025-01-12T20:31:25.592123Z",
     "iopub.status.idle": "2025-01-12T20:31:31.363617Z",
     "shell.execute_reply": "2025-01-12T20:31:31.362352Z"
    },
    "papermill": {
     "duration": 5.781732,
     "end_time": "2025-01-12T20:31:31.365764",
     "exception": false,
     "start_time": "2025-01-12T20:31:25.584032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pip-install-lifelines/fonttools-4.55.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/tzdata-2024.2-py2.py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/pillow-11.0.0-cp310-cp310-manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/pyparsing-3.2.0-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/wrapt-1.17.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/__results__.html\n",
      "/kaggle/input/pip-install-lifelines/cycler-0.12.1-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/numpy-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/six-1.17.0-py2.py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
      "/kaggle/input/pip-install-lifelines/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/__notebook__.ipynb\n",
      "/kaggle/input/pip-install-lifelines/__output__.json\n",
      "/kaggle/input/pip-install-lifelines/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/pytz-2024.2-py2.py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pip-install-lifelines/packaging-24.2-py3-none-any.whl\n",
      "/kaggle/input/pip-install-lifelines/custom.css\n",
      "/kaggle/input/experimentation123/experimentation3.ipynb\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/sample_submission.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/data_dictionary.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/train.csv\n",
      "/kaggle/input/equity-post-HCT-survival-predictions/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "pd.set_option(\"display.max_columns\" , 100)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold , KFold\n",
    "from xgboost import XGBRegressor \n",
    "from catboost import CatBoostRegressor \n",
    "from lightgbm import LGBMRegressor\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from autograd import grad as get_gradient\n",
    "import sympy as sp\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d80e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:31.379741Z",
     "iopub.status.busy": "2025-01-12T20:31:31.379038Z",
     "iopub.status.idle": "2025-01-12T20:31:55.373375Z",
     "shell.execute_reply": "2025-01-12T20:31:55.372114Z"
    },
    "papermill": {
     "duration": 24.003124,
     "end_time": "2025-01-12T20:31:55.375268",
     "exception": false,
     "start_time": "2025-01-12T20:31:31.372144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd==1.7.0) (1.26.4)\r\n",
      "autograd is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Processing /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: autograd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.7.0)\r\n",
      "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autograd-gamma==0.5.0) (1.13.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from autograd>=1.2.0->autograd-gamma==0.5.0) (1.26.4)\r\n",
      "Building wheels for collected packages: autograd-gamma\r\n",
      "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4031 sha256=ac89a2552fb98cf5366b1bac69620013a0ef709a17907bd65443e7213324a2ad\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/6b/b5/e0/4c79e15c0b5f2c15ecf613c720bb20daab20a666eb67135155\r\n",
      "Successfully built autograd-gamma\r\n",
      "Installing collected packages: autograd-gamma\r\n",
      "Successfully installed autograd-gamma-0.5.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\r\n",
      "Installing collected packages: interface-meta\r\n",
      "Successfully installed interface-meta-1.3.0\r\n",
      "Processing /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.26.4)\r\n",
      "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (2.1.4)\r\n",
      "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.13.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic==1.0.2) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->formulaic==1.0.2) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic==1.0.2) (1.16.0)\r\n",
      "Installing collected packages: formulaic\r\n",
      "Successfully installed formulaic-1.0.2\r\n",
      "Processing /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.13.1)\r\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (2.1.4)\r\n",
      "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (3.7.1)\r\n",
      "Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.7.0)\r\n",
      "Requirement already satisfied: autograd-gamma>=0.3 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (0.5.0)\r\n",
      "Requirement already satisfied: formulaic>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from lifelines==0.30.0) (1.0.2)\r\n",
      "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=0.2.2->lifelines==0.30.0) (1.16.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.3.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (4.53.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (24.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (10.4.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (3.1.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0->lifelines==0.30.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->lifelines==0.30.0) (2024.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines==0.30.0) (1.16.0)\r\n",
      "Installing collected packages: lifelines\r\n",
      "Successfully installed lifelines-0.30.0\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !pip install /kaggle/input/pip-install-lifelines/autograd-1.7.0-py3-none-any.whl\n",
    "# !pip install /kaggle/input/pip-install-lifelines/autograd-gamma-0.5.0.tar.gz\n",
    "# !pip install /kaggle/input/pip-install-lifelines/interface_meta-1.3.0-py3-none-any.whl\n",
    "# !pip install /kaggle/input/pip-install-lifelines/formulaic-1.0.2-py3-none-any.whl\n",
    "# !pip install /kaggle/input/pip-install-lifelines/lifelines-0.30.0-py3-none-any.whl\n",
    "\n",
    "# # !pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f2de429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:55.390041Z",
     "iopub.status.busy": "2025-01-12T20:31:55.389703Z",
     "iopub.status.idle": "2025-01-12T20:31:55.865171Z",
     "shell.execute_reply": "2025-01-12T20:31:55.864157Z"
    },
    "papermill": {
     "duration": 0.485639,
     "end_time": "2025-01-12T20:31:55.867757",
     "exception": false,
     "start_time": "2025-01-12T20:31:55.382118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>vent_hist</th>\n",
       "      <th>renal_issue</th>\n",
       "      <th>pulm_severe</th>\n",
       "      <th>prim_disease_hct</th>\n",
       "      <th>hla_high_res_6</th>\n",
       "      <th>cmv_status</th>\n",
       "      <th>hla_high_res_10</th>\n",
       "      <th>hla_match_dqb1_high</th>\n",
       "      <th>tce_imm_match</th>\n",
       "      <th>hla_nmdp_6</th>\n",
       "      <th>hla_match_c_low</th>\n",
       "      <th>rituximab</th>\n",
       "      <th>hla_match_drb1_low</th>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <th>prod_type</th>\n",
       "      <th>cyto_score_detail</th>\n",
       "      <th>conditioning_intensity</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>year_hct</th>\n",
       "      <th>obesity</th>\n",
       "      <th>mrd_hct</th>\n",
       "      <th>in_vivo_tcd</th>\n",
       "      <th>tce_match</th>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <th>hepatic_severe</th>\n",
       "      <th>donor_age</th>\n",
       "      <th>prior_tumor</th>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <th>peptic_ulcer</th>\n",
       "      <th>age_at_hct</th>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <th>gvhd_proph</th>\n",
       "      <th>rheum_issue</th>\n",
       "      <th>sex_match</th>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <th>race_group</th>\n",
       "      <th>comorbidity_score</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "      <th>efs_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>IEA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2016</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>9.942</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FKalone</td>\n",
       "      <td>No</td>\n",
       "      <td>M-F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than one race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TBI +- Other, &gt;cGy</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>AML</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2008</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>72.290</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>43.705</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Other GVHD Prophylaxis</td>\n",
       "      <td>No</td>\n",
       "      <td>F-F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>HIS</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2019</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>33.997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cyclophosphamide alone</td>\n",
       "      <td>No</td>\n",
       "      <td>F-M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than one race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>ALL</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BM</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2009</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>29.230</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>43.245</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FK+ MMF +- others</td>\n",
       "      <td>No</td>\n",
       "      <td>M-M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>White</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>MPN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2018</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>56.810</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>29.740</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TDEPLETION +- other</td>\n",
       "      <td>No</td>\n",
       "      <td>M-F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>American Indian or Alaska Native</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>28795</td>\n",
       "      <td>Intermediate - TED AML case &lt;missing cytogenetics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Favorable</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALL</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-/-</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2018</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fully matched</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>24.212</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>51.136</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FK+ MTX +- others(not MMF)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>More than one race</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bi-directional non-permissive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>28796</td>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>AML</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-/+</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>G/G</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>TBD</td>\n",
       "      <td>RIC</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2017</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>30.770</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>18.075</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cyclophosphamide +- others</td>\n",
       "      <td>No</td>\n",
       "      <td>M-F</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Native Hawaiian or other Pacific Islander</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>GvH non-permissive</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>28797</td>\n",
       "      <td>TBD cytogenetics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Poor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IPA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>G/G</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>Poor</td>\n",
       "      <td>MAC</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2018</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>GvH non-permissive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>22.627</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>FK+ MMF +- others</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Native Hawaiian or other Pacific Islander</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GvH non-permissive</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>28798</td>\n",
       "      <td>N/A - non-malignant indication</td>\n",
       "      <td>No</td>\n",
       "      <td>Poor</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IPA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NMA</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>58.074</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cyclophosphamide alone</td>\n",
       "      <td>No</td>\n",
       "      <td>M-M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>28799</td>\n",
       "      <td>N/A - pediatric</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>SAA</td>\n",
       "      <td>6.0</td>\n",
       "      <td>+/+</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>P/P</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Hispanic or Latino</td>\n",
       "      <td>2018</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>30.571</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>1.035</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cyclophosphamide +- others</td>\n",
       "      <td>No</td>\n",
       "      <td>M-M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                          dri_score psych_disturb  \\\n",
       "0          0                     N/A - non-malignant indication            No   \n",
       "1          1                                       Intermediate            No   \n",
       "2          2                     N/A - non-malignant indication            No   \n",
       "3          3                                               High            No   \n",
       "4          4                                               High            No   \n",
       "...      ...                                                ...           ...   \n",
       "28795  28795  Intermediate - TED AML case <missing cytogenetics           NaN   \n",
       "28796  28796                                               High            No   \n",
       "28797  28797                                   TBD cytogenetics           NaN   \n",
       "28798  28798                     N/A - non-malignant indication            No   \n",
       "28799  28799                                    N/A - pediatric            No   \n",
       "\n",
       "         cyto_score diabetes  hla_match_c_high  hla_high_res_8  \\\n",
       "0               NaN       No               NaN             NaN   \n",
       "1      Intermediate       No               2.0             8.0   \n",
       "2               NaN       No               2.0             8.0   \n",
       "3      Intermediate       No               2.0             8.0   \n",
       "4               NaN       No               2.0             8.0   \n",
       "...             ...      ...               ...             ...   \n",
       "28795     Favorable       No               2.0             8.0   \n",
       "28796          Poor      Yes               1.0             4.0   \n",
       "28797          Poor      NaN               2.0             8.0   \n",
       "28798          Poor       No               1.0             4.0   \n",
       "28799           NaN       No               2.0             8.0   \n",
       "\n",
       "               tbi_status arrhythmia  hla_low_res_6        graft_type  \\\n",
       "0                  No TBI         No            6.0       Bone marrow   \n",
       "1      TBI +- Other, >cGy         No            6.0  Peripheral blood   \n",
       "2                  No TBI         No            6.0       Bone marrow   \n",
       "3                  No TBI         No            6.0       Bone marrow   \n",
       "4                  No TBI         No            6.0  Peripheral blood   \n",
       "...                   ...        ...            ...               ...   \n",
       "28795              No TBI         No            6.0  Peripheral blood   \n",
       "28796              No TBI         No            5.0  Peripheral blood   \n",
       "28797              No TBI        NaN            6.0  Peripheral blood   \n",
       "28798              No TBI         No            3.0  Peripheral blood   \n",
       "28799              No TBI         No            6.0       Bone marrow   \n",
       "\n",
       "      vent_hist renal_issue pulm_severe prim_disease_hct  hla_high_res_6  \\\n",
       "0            No          No          No              IEA             6.0   \n",
       "1            No          No          No              AML             6.0   \n",
       "2            No          No          No              HIS             6.0   \n",
       "3            No          No          No              ALL             6.0   \n",
       "4            No          No          No              MPN             6.0   \n",
       "...         ...         ...         ...              ...             ...   \n",
       "28795        No          No         NaN              ALL             6.0   \n",
       "28796        No          No          No              AML             3.0   \n",
       "28797        No         NaN         NaN              IPA             6.0   \n",
       "28798        No         NaN         NaN              IPA             3.0   \n",
       "28799        No          No          No              SAA             6.0   \n",
       "\n",
       "      cmv_status  hla_high_res_10  hla_match_dqb1_high tce_imm_match  \\\n",
       "0            +/+              NaN                  2.0           NaN   \n",
       "1            +/+             10.0                  2.0           P/P   \n",
       "2            +/+             10.0                  2.0           P/P   \n",
       "3            +/+             10.0                  2.0           P/P   \n",
       "4            +/+             10.0                  2.0           NaN   \n",
       "...          ...              ...                  ...           ...   \n",
       "28795        -/-             10.0                  2.0           P/P   \n",
       "28796        -/+              6.0                  2.0           G/G   \n",
       "28797        -/+             10.0                  2.0           G/G   \n",
       "28798        +/+              5.0                  1.0           P/P   \n",
       "28799        +/+             10.0                  2.0           P/P   \n",
       "\n",
       "       hla_nmdp_6  hla_match_c_low rituximab  hla_match_drb1_low  \\\n",
       "0             6.0              2.0        No                 2.0   \n",
       "1             6.0              2.0        No                 2.0   \n",
       "2             6.0              2.0        No                 2.0   \n",
       "3             6.0              2.0        No                 2.0   \n",
       "4             5.0              2.0        No                 2.0   \n",
       "...           ...              ...       ...                 ...   \n",
       "28795         6.0              2.0        No                 2.0   \n",
       "28796         4.0              1.0        No                 2.0   \n",
       "28797         6.0              2.0       NaN                 2.0   \n",
       "28798         3.0              1.0        No                 1.0   \n",
       "28799         6.0              2.0        No                 2.0   \n",
       "\n",
       "       hla_match_dqb1_low prod_type cyto_score_detail conditioning_intensity  \\\n",
       "0                     2.0        BM               NaN                    NaN   \n",
       "1                     2.0        PB      Intermediate                    MAC   \n",
       "2                     2.0        BM               NaN                    NaN   \n",
       "3                     2.0        BM      Intermediate                    MAC   \n",
       "4                     2.0        PB               NaN                    MAC   \n",
       "...                   ...       ...               ...                    ...   \n",
       "28795                 2.0        PB      Intermediate                    MAC   \n",
       "28796                 2.0        PB               TBD                    RIC   \n",
       "28797                 2.0        PB              Poor                    MAC   \n",
       "28798                 1.0        PB               NaN                    NMA   \n",
       "28799                 2.0        BM               NaN                    NaN   \n",
       "\n",
       "                    ethnicity  year_hct obesity   mrd_hct in_vivo_tcd  \\\n",
       "0      Not Hispanic or Latino      2016      No       NaN         Yes   \n",
       "1      Not Hispanic or Latino      2008      No  Positive          No   \n",
       "2      Not Hispanic or Latino      2019      No       NaN         Yes   \n",
       "3      Not Hispanic or Latino      2009      No  Positive          No   \n",
       "4          Hispanic or Latino      2018      No       NaN         Yes   \n",
       "...                       ...       ...     ...       ...         ...   \n",
       "28795  Not Hispanic or Latino      2018      No  Negative         Yes   \n",
       "28796      Hispanic or Latino      2017      No  Positive          No   \n",
       "28797  Not Hispanic or Latino      2018      No       NaN          No   \n",
       "28798  Not Hispanic or Latino      2018     NaN       NaN         Yes   \n",
       "28799  Not Hispanic or Latino      2018      No       NaN         Yes   \n",
       "\n",
       "                tce_match  hla_match_a_high hepatic_severe  donor_age  \\\n",
       "0                     NaN               2.0             No        NaN   \n",
       "1              Permissive               2.0             No     72.290   \n",
       "2                     NaN               2.0             No        NaN   \n",
       "3              Permissive               2.0             No     29.230   \n",
       "4                     NaN               2.0             No     56.810   \n",
       "...                   ...               ...            ...        ...   \n",
       "28795       Fully matched               2.0             No     24.212   \n",
       "28796                 NaN               1.0             No     30.770   \n",
       "28797  GvH non-permissive               2.0             No     22.627   \n",
       "28798                 NaN               1.0             No     58.074   \n",
       "28799                 NaN               2.0             No     30.571   \n",
       "\n",
       "      prior_tumor  hla_match_b_low peptic_ulcer  age_at_hct  hla_match_a_low  \\\n",
       "0              No              2.0           No       9.942              2.0   \n",
       "1              No              2.0           No      43.705              2.0   \n",
       "2              No              2.0           No      33.997              2.0   \n",
       "3              No              2.0           No      43.245              2.0   \n",
       "4              No              2.0           No      29.740              2.0   \n",
       "...           ...              ...          ...         ...              ...   \n",
       "28795         Yes              2.0           No      51.136              2.0   \n",
       "28796          No              1.0           No      18.075              2.0   \n",
       "28797          No              2.0          NaN      51.005              2.0   \n",
       "28798         Yes              1.0          NaN       0.044              1.0   \n",
       "28799          No              2.0           No       1.035              2.0   \n",
       "\n",
       "                       gvhd_proph rheum_issue sex_match  hla_match_b_high  \\\n",
       "0                         FKalone          No       M-F               2.0   \n",
       "1          Other GVHD Prophylaxis          No       F-F               2.0   \n",
       "2          Cyclophosphamide alone          No       F-M               2.0   \n",
       "3               FK+ MMF +- others          No       M-M               2.0   \n",
       "4             TDEPLETION +- other          No       M-F               2.0   \n",
       "...                           ...         ...       ...               ...   \n",
       "28795  FK+ MTX +- others(not MMF)         NaN       M-F               2.0   \n",
       "28796  Cyclophosphamide +- others          No       M-F               1.0   \n",
       "28797           FK+ MMF +- others         NaN       M-F               2.0   \n",
       "28798      Cyclophosphamide alone          No       M-M               1.0   \n",
       "28799  Cyclophosphamide +- others          No       M-M               2.0   \n",
       "\n",
       "                                      race_group  comorbidity_score  \\\n",
       "0                             More than one race                0.0   \n",
       "1                                          Asian                3.0   \n",
       "2                             More than one race                0.0   \n",
       "3                                          White                0.0   \n",
       "4               American Indian or Alaska Native                1.0   \n",
       "...                                          ...                ...   \n",
       "28795                         More than one race                0.0   \n",
       "28796  Native Hawaiian or other Pacific Islander                3.0   \n",
       "28797  Native Hawaiian or other Pacific Islander                5.0   \n",
       "28798                  Black or African-American                1.0   \n",
       "28799                  Black or African-American                2.0   \n",
       "\n",
       "       karnofsky_score hepatic_mild                  tce_div_match  \\\n",
       "0                 90.0           No                            NaN   \n",
       "1                 90.0           No          Permissive mismatched   \n",
       "2                 90.0           No          Permissive mismatched   \n",
       "3                 90.0          Yes          Permissive mismatched   \n",
       "4                 90.0           No          Permissive mismatched   \n",
       "...                ...          ...                            ...   \n",
       "28795              NaN          NaN  Bi-directional non-permissive   \n",
       "28796             90.0           No             GvH non-permissive   \n",
       "28797             90.0          NaN             GvH non-permissive   \n",
       "28798             90.0           No          Permissive mismatched   \n",
       "28799             90.0           No          Permissive mismatched   \n",
       "\n",
       "      donor_related      melphalan_dose  hla_low_res_8 cardiac  \\\n",
       "0         Unrelated  N/A, Mel not given            8.0      No   \n",
       "1           Related  N/A, Mel not given            8.0      No   \n",
       "2           Related  N/A, Mel not given            8.0      No   \n",
       "3         Unrelated  N/A, Mel not given            8.0      No   \n",
       "4           Related                 MEL            8.0      No   \n",
       "...             ...                 ...            ...     ...   \n",
       "28795           NaN  N/A, Mel not given            8.0     NaN   \n",
       "28796       Related  N/A, Mel not given            6.0     Yes   \n",
       "28797     Unrelated  N/A, Mel not given            8.0     NaN   \n",
       "28798       Related                 MEL            4.0      No   \n",
       "28799       Related                 MEL            8.0      No   \n",
       "\n",
       "       hla_match_drb1_high pulm_moderate  hla_low_res_10  efs  efs_time  \n",
       "0                      2.0            No            10.0  0.0    42.356  \n",
       "1                      2.0           Yes            10.0  1.0     4.672  \n",
       "2                      2.0            No            10.0  0.0    19.793  \n",
       "3                      2.0            No            10.0  0.0   102.349  \n",
       "4                      2.0            No            10.0  0.0    16.223  \n",
       "...                    ...           ...             ...  ...       ...  \n",
       "28795                  2.0            No            10.0  0.0    18.633  \n",
       "28796                  1.0           Yes             8.0  1.0     4.892  \n",
       "28797                  2.0            No            10.0  0.0    23.157  \n",
       "28798                  1.0            No             5.0  0.0    52.351  \n",
       "28799                  2.0           Yes            10.0  0.0    25.158  \n",
       "\n",
       "[28800 rows x 60 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n",
    "test = pd.read_csv(\"/kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6655df5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:55.885901Z",
     "iopub.status.busy": "2025-01-12T20:31:55.885490Z",
     "iopub.status.idle": "2025-01-12T20:31:55.982699Z",
     "shell.execute_reply": "2025-01-12T20:31:55.981579Z"
    },
    "papermill": {
     "duration": 0.109185,
     "end_time": "2025-01-12T20:31:55.985099",
     "exception": false,
     "start_time": "2025-01-12T20:31:55.875914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.api.types\n",
    "import numpy as np\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    \"\"\"\n",
    "    >>> import pandas as pd\n",
    "    >>> row_id_column_name = \"id\"\n",
    "    >>> y_pred = {'prediction': {0: 1.0, 1: 0.0, 2: 1.0}}\n",
    "    >>> y_pred = pd.DataFrame(y_pred)\n",
    "    >>> y_pred.insert(0, row_id_column_name, range(len(y_pred)))\n",
    "    >>> y_true = { 'efs': {0: 1.0, 1: 0.0, 2: 0.0}, 'efs_time': {0: 25.1234,1: 250.1234,2: 2500.1234}, 'race_group': {0: 'race_group_1', 1: 'race_group_1', 2: 'race_group_1'}}\n",
    "    >>> y_true = pd.DataFrame(y_true)\n",
    "    >>> y_true.insert(0, row_id_column_name, range(len(y_true)))\n",
    "    >>> score(y_true.copy(), y_pred.copy(), row_id_column_name)\n",
    "    0.75\n",
    "    \"\"\"\n",
    "    \n",
    "    del solution[row_id_column_name]\n",
    "    del submission[row_id_column_name]\n",
    "    \n",
    "    event_label = 'efs'\n",
    "    interval_label = 'efs_time'\n",
    "    prediction_label = 'prediction'\n",
    "    for col in submission.columns:\n",
    "        if not pandas.api.types.is_numeric_dtype(submission[col]):\n",
    "            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n",
    "    # Merging solution and submission dfs on ID\n",
    "    merged_df = pd.concat([solution, submission], axis=1)\n",
    "    merged_df.reset_index(inplace=True)\n",
    "    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n",
    "    metric_list = []\n",
    "    for race in merged_df_race_dict.keys():\n",
    "        # Retrieving values from y_test based on index\n",
    "        indices = sorted(merged_df_race_dict[race])\n",
    "        merged_df_race = merged_df.iloc[indices]\n",
    "        # Calculate the concordance index\n",
    "        c_index_race = concordance_index(\n",
    "                        merged_df_race[interval_label],\n",
    "                        -merged_df_race[prediction_label],\n",
    "                        merged_df_race[event_label])\n",
    "        metric_list.append(c_index_race)\n",
    "    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))\n",
    "\n",
    "def evaluate(train = train , oof = None , scoring_func = score , print_=True):\n",
    "    y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "    y_pred = train[[\"ID\"]].copy()\n",
    "    y_pred[\"prediction\"] = oof\n",
    "    m = scoring_func(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "    if print_:\n",
    "        print(f\"score is {m}\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77ee96a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.002505Z",
     "iopub.status.busy": "2025-01-12T20:31:56.001836Z",
     "iopub.status.idle": "2025-01-12T20:31:56.021057Z",
     "shell.execute_reply": "2025-01-12T20:31:56.020296Z"
    },
    "papermill": {
     "duration": 0.029288,
     "end_time": "2025-01-12T20:31:56.022780",
     "exception": false,
     "start_time": "2025-01-12T20:31:55.993492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_efs_time = train[\"efs_time\"].values\n",
    "default_efs = train[\"efs\"].values\n",
    "default_groups = train[\"race_group\"].astype(\"category\").factorize()[0]\n",
    "\n",
    "def evaluate_(pred = None  , indices = None ,groups = default_groups , efs = default_efs , efs_time = default_efs_time):\n",
    "    efs_time = efs_time[indices]\n",
    "    efs = efs[indices]\n",
    "    in_groups = default_groups[indices]\n",
    "\n",
    "    scores = np.zeros(6)\n",
    "    for i in range(6):\n",
    "        curr_indices = np.where(in_groups == i)[0]\n",
    "        score_ = concordance_index(efs_time[curr_indices] \n",
    "                                   , -pred[curr_indices] \n",
    "                                   , efs[curr_indices])\n",
    "        scores[i] = score_\n",
    "    \n",
    "    return np.mean(scores)-np.sqrt(np.var(scores))\n",
    "\n",
    "\n",
    "# evaluate_(pred = pred , indices = train_test.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "949d91de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.039039Z",
     "iopub.status.busy": "2025-01-12T20:31:56.038716Z",
     "iopub.status.idle": "2025-01-12T20:31:56.049411Z",
     "shell.execute_reply": "2025-01-12T20:31:56.048379Z"
    },
    "papermill": {
     "duration": 0.020715,
     "end_time": "2025-01-12T20:31:56.051090",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.030375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(train = train , oof = None , scoring_func = score , print_=True):\n",
    "    y_true = train[[\"ID\",\"efs\",\"efs_time\",\"race_group\"]].copy()\n",
    "    y_pred = train[[\"ID\"]].copy()\n",
    "    y_pred[\"prediction\"] = oof\n",
    "    m = scoring_func(y_true.copy(), y_pred.copy(), \"ID\")\n",
    "    if print_:\n",
    "        print(f\"score is {m}\")\n",
    "    return m\n",
    "\n",
    "# def wrap(indices = None):\n",
    "#     def target_metric_(y_true , y_pred ):\n",
    "#         score = evaluate_(pred = y_pred , indices = indices )\n",
    "#         return 1-score\n",
    "#     return target_metric_\n",
    "\n",
    "def kfold_cv(model , X_train : pd.DataFrame, y_train:pd.Series,callback =None , callback_params = None , n_splits=5 , model_type = \"xgb\" , cat_features=None, verbose = 0 , scaler = None , use_tqdm = True , data =train , evaluate=False):\n",
    "    # Initialize KFold\n",
    "    add = []\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)                  \n",
    "    oof_predictions = np.zeros(len(X_train))\n",
    "    fold_iterator = enumerate(kf.split(X_train, y_train))\n",
    "    if use_tqdm:\n",
    "        fold_iterator = tqdm(fold_iterator, total=n_splits)        \n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in fold_iterator:\n",
    "        \n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train_fold, X_valid_fold = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "\n",
    "            y_train_fold, y_valid_fold = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        model_ = clone(model)\n",
    "\n",
    "\n",
    "        #FITTING LOGIC\n",
    "        if model_type in [\"xgb\"]:\n",
    "            callback_ = callback(**callback_params)\n",
    "            callback_.testing_data = X_valid_fold\n",
    "            model_.fit(X_train_fold , y_train_fold\n",
    "                       ,eval_set=[(X_valid_fold , y_valid_fold)] \n",
    "                       , verbose = verbose , callbacks = [callback_])\n",
    "            try:\n",
    "                add.append(model_.best_iteration)\n",
    "            except:\n",
    "                add.append(0)\n",
    "            \n",
    "        elif model_type in [\"lgbm\"]:\n",
    "            model_.fit(X_train_fold , y_train_fold,\n",
    "                       eval_set=[(X_valid_fold, y_valid_fold)])\n",
    "        elif model_type in [\"catboost\"]:\n",
    "            model_.fit(X_train_fold , y_train_fold \n",
    "                       , cat_features = cat_features if cat_features else None\n",
    "                      ,eval_set=[(X_train_fold , y_train_fold) ,(X_valid_fold, y_valid_fold)]\n",
    "                      )\n",
    "\n",
    "        else :\n",
    "            model_.fit(X_train_fold , y_train_fold )\n",
    "\n",
    "        \n",
    "        pred = model_.predict(X_valid_fold).reshape(-1 ,)\n",
    "        \n",
    "        oof_predictions[valid_idx] = pred\n",
    "\n",
    "    try:\n",
    "        print(f\"best_iterations -> {add} -> {float(np.mean(add))}\")\n",
    "    except:\n",
    "        pass\n",
    "    return oof_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4957a3cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.067797Z",
     "iopub.status.busy": "2025-01-12T20:31:56.067454Z",
     "iopub.status.idle": "2025-01-12T20:31:56.751369Z",
     "shell.execute_reply": "2025-01-12T20:31:56.750405Z"
    },
    "papermill": {
     "duration": 0.694213,
     "end_time": "2025-01-12T20:31:56.753095",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.058882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "def transform_target(time_col = \"efs_time\" , event_col = \"efs\" , data = train):\n",
    "    kmp = KaplanMeierFitter()\n",
    "    kmp.fit(data[time_col] , data[event_col])\n",
    "    y_combined = kmp.survival_function_at_times(train[time_col]).values\n",
    "    return y_combined\n",
    "\n",
    "train[\"y\"] = transform_target(time_col = \"efs_time\" , event_col = \"efs\" , data = train)\n",
    "\n",
    "plt.figure(figsize = (15 , 6))\n",
    "plt.hist(train.loc[train.efs==1 , \"y\"] , bins = 100 , label = \"efc = 1 (y)\")\n",
    "plt.hist(train.loc[train.efs==0 , \"y\"] , bins = 100 , label = \"efc = 0 (y)\")\n",
    "\n",
    "plt.xlabel(\"Transformed Target y\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"KaplanMeier Transformed Target y using both efs and efs_time.\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0bf026c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.771106Z",
     "iopub.status.busy": "2025-01-12T20:31:56.770784Z",
     "iopub.status.idle": "2025-01-12T20:31:56.930358Z",
     "shell.execute_reply": "2025-01-12T20:31:56.929414Z"
    },
    "papermill": {
     "duration": 0.170693,
     "end_time": "2025-01-12T20:31:56.932359",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.761666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>vent_hist</th>\n",
       "      <th>renal_issue</th>\n",
       "      <th>pulm_severe</th>\n",
       "      <th>prim_disease_hct</th>\n",
       "      <th>hla_high_res_6</th>\n",
       "      <th>cmv_status</th>\n",
       "      <th>hla_high_res_10</th>\n",
       "      <th>hla_match_dqb1_high</th>\n",
       "      <th>tce_imm_match</th>\n",
       "      <th>hla_nmdp_6</th>\n",
       "      <th>hla_match_c_low</th>\n",
       "      <th>rituximab</th>\n",
       "      <th>hla_match_drb1_low</th>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <th>prod_type</th>\n",
       "      <th>cyto_score_detail</th>\n",
       "      <th>conditioning_intensity</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>year_hct</th>\n",
       "      <th>obesity</th>\n",
       "      <th>mrd_hct</th>\n",
       "      <th>in_vivo_tcd</th>\n",
       "      <th>tce_match</th>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <th>hepatic_severe</th>\n",
       "      <th>donor_age</th>\n",
       "      <th>prior_tumor</th>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <th>peptic_ulcer</th>\n",
       "      <th>age_at_hct</th>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <th>gvhd_proph</th>\n",
       "      <th>rheum_issue</th>\n",
       "      <th>sex_match</th>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <th>race_group</th>\n",
       "      <th>comorbidity_score</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "      <th>efs_time</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.942</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.356</td>\n",
       "      <td>0.458687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72.290</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.705</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.672</td>\n",
       "      <td>0.847759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.997</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.793</td>\n",
       "      <td>0.462424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.230</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.245</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.349</td>\n",
       "      <td>0.456661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>56.810</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.740</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.223</td>\n",
       "      <td>0.464674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28795</th>\n",
       "      <td>28795</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.212</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51.136</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.633</td>\n",
       "      <td>0.462846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28796</th>\n",
       "      <td>28796</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.075</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.892</td>\n",
       "      <td>0.825494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28797</th>\n",
       "      <td>28797</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.627</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.005</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.157</td>\n",
       "      <td>0.461142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28798</th>\n",
       "      <td>28798</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.074</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.351</td>\n",
       "      <td>0.458404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28799</th>\n",
       "      <td>28799</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.571</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.035</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.158</td>\n",
       "      <td>0.460616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28800 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  dri_score  psych_disturb  cyto_score  diabetes  \\\n",
       "0          0          1              1           0         1   \n",
       "1          1          2              1           1         1   \n",
       "2          2          1              1           0         1   \n",
       "3          3          3              1           1         1   \n",
       "4          4          3              1           0         1   \n",
       "...      ...        ...            ...         ...       ...   \n",
       "28795  28795          8              0           4         1   \n",
       "28796  28796          3              1           2         2   \n",
       "28797  28797          7              0           2         0   \n",
       "28798  28798          1              1           2         1   \n",
       "28799  28799          6              1           0         1   \n",
       "\n",
       "       hla_match_c_high  hla_high_res_8  tbi_status  arrhythmia  \\\n",
       "0                   NaN             NaN           0           1   \n",
       "1                   2.0             8.0           1           1   \n",
       "2                   2.0             8.0           0           1   \n",
       "3                   2.0             8.0           0           1   \n",
       "4                   2.0             8.0           0           1   \n",
       "...                 ...             ...         ...         ...   \n",
       "28795               2.0             8.0           0           1   \n",
       "28796               1.0             4.0           0           1   \n",
       "28797               2.0             8.0           0           0   \n",
       "28798               1.0             4.0           0           1   \n",
       "28799               2.0             8.0           0           1   \n",
       "\n",
       "       hla_low_res_6  graft_type  vent_hist  renal_issue  pulm_severe  \\\n",
       "0                6.0           0          1            1            1   \n",
       "1                6.0           1          1            1            1   \n",
       "2                6.0           0          1            1            1   \n",
       "3                6.0           0          1            1            1   \n",
       "4                6.0           1          1            1            1   \n",
       "...              ...         ...        ...          ...          ...   \n",
       "28795            6.0           1          1            1            0   \n",
       "28796            5.0           1          1            1            1   \n",
       "28797            6.0           1          1            0            0   \n",
       "28798            3.0           1          1            0            0   \n",
       "28799            6.0           0          1            1            1   \n",
       "\n",
       "       prim_disease_hct  hla_high_res_6  cmv_status  hla_high_res_10  \\\n",
       "0                     0             6.0           1              NaN   \n",
       "1                     1             6.0           1             10.0   \n",
       "2                     2             6.0           1             10.0   \n",
       "3                     3             6.0           1             10.0   \n",
       "4                     4             6.0           1             10.0   \n",
       "...                 ...             ...         ...              ...   \n",
       "28795                 3             6.0           3             10.0   \n",
       "28796                 1             3.0           2              6.0   \n",
       "28797                 9             6.0           2             10.0   \n",
       "28798                 9             3.0           1              5.0   \n",
       "28799                13             6.0           1             10.0   \n",
       "\n",
       "       hla_match_dqb1_high  tce_imm_match  hla_nmdp_6  hla_match_c_low  \\\n",
       "0                      2.0              0         6.0              2.0   \n",
       "1                      2.0              1         6.0              2.0   \n",
       "2                      2.0              1         6.0              2.0   \n",
       "3                      2.0              1         6.0              2.0   \n",
       "4                      2.0              0         5.0              2.0   \n",
       "...                    ...            ...         ...              ...   \n",
       "28795                  2.0              1         6.0              2.0   \n",
       "28796                  2.0              4         4.0              1.0   \n",
       "28797                  2.0              4         6.0              2.0   \n",
       "28798                  1.0              1         3.0              1.0   \n",
       "28799                  2.0              1         6.0              2.0   \n",
       "\n",
       "       rituximab  hla_match_drb1_low  hla_match_dqb1_low  prod_type  \\\n",
       "0              1                 2.0                 2.0          0   \n",
       "1              1                 2.0                 2.0          1   \n",
       "2              1                 2.0                 2.0          0   \n",
       "3              1                 2.0                 2.0          0   \n",
       "4              1                 2.0                 2.0          1   \n",
       "...          ...                 ...                 ...        ...   \n",
       "28795          1                 2.0                 2.0          1   \n",
       "28796          1                 2.0                 2.0          1   \n",
       "28797          0                 2.0                 2.0          1   \n",
       "28798          1                 1.0                 1.0          1   \n",
       "28799          1                 2.0                 2.0          0   \n",
       "\n",
       "       cyto_score_detail  conditioning_intensity  ethnicity  year_hct  \\\n",
       "0                      0                       0          1      2016   \n",
       "1                      1                       1          1      2008   \n",
       "2                      0                       0          1      2019   \n",
       "3                      1                       1          1      2009   \n",
       "4                      0                       1          2      2018   \n",
       "...                  ...                     ...        ...       ...   \n",
       "28795                  1                       1          1      2018   \n",
       "28796                  2                       2          2      2017   \n",
       "28797                  3                       1          1      2018   \n",
       "28798                  0                       3          1      2018   \n",
       "28799                  0                       0          1      2018   \n",
       "\n",
       "       obesity  mrd_hct  in_vivo_tcd  tce_match  hla_match_a_high  \\\n",
       "0            1        0            1          0               2.0   \n",
       "1            1        1            2          1               2.0   \n",
       "2            1        0            1          0               2.0   \n",
       "3            1        1            2          1               2.0   \n",
       "4            1        0            1          0               2.0   \n",
       "...        ...      ...          ...        ...               ...   \n",
       "28795        1        2            1          3               2.0   \n",
       "28796        1        1            2          0               1.0   \n",
       "28797        1        0            2          4               2.0   \n",
       "28798        0        0            1          0               1.0   \n",
       "28799        1        0            1          0               2.0   \n",
       "\n",
       "       hepatic_severe  donor_age  prior_tumor  hla_match_b_low  peptic_ulcer  \\\n",
       "0                   1        NaN            1              2.0             1   \n",
       "1                   1     72.290            1              2.0             1   \n",
       "2                   1        NaN            1              2.0             1   \n",
       "3                   1     29.230            1              2.0             1   \n",
       "4                   1     56.810            1              2.0             1   \n",
       "...               ...        ...          ...              ...           ...   \n",
       "28795               1     24.212            2              2.0             1   \n",
       "28796               1     30.770            1              1.0             1   \n",
       "28797               1     22.627            1              2.0             0   \n",
       "28798               1     58.074            2              1.0             0   \n",
       "28799               1     30.571            1              2.0             1   \n",
       "\n",
       "       age_at_hct  hla_match_a_low  gvhd_proph  rheum_issue  sex_match  \\\n",
       "0           9.942              2.0           1            1          1   \n",
       "1          43.705              2.0           2            1          2   \n",
       "2          33.997              2.0           3            1          3   \n",
       "3          43.245              2.0           4            1          4   \n",
       "4          29.740              2.0           5            1          1   \n",
       "...           ...              ...         ...          ...        ...   \n",
       "28795      51.136              2.0           8            0          1   \n",
       "28796      18.075              2.0           9            1          1   \n",
       "28797      51.005              2.0           4            0          1   \n",
       "28798       0.044              1.0           3            1          4   \n",
       "28799       1.035              2.0           9            1          4   \n",
       "\n",
       "       hla_match_b_high  race_group  comorbidity_score  karnofsky_score  \\\n",
       "0                   2.0           0                0.0             90.0   \n",
       "1                   2.0           1                3.0             90.0   \n",
       "2                   2.0           0                0.0             90.0   \n",
       "3                   2.0           2                0.0             90.0   \n",
       "4                   2.0           3                1.0             90.0   \n",
       "...                 ...         ...                ...              ...   \n",
       "28795               2.0           0                0.0              NaN   \n",
       "28796               1.0           4                3.0             90.0   \n",
       "28797               2.0           4                5.0             90.0   \n",
       "28798               1.0           5                1.0             90.0   \n",
       "28799               2.0           5                2.0             90.0   \n",
       "\n",
       "       hepatic_mild  tce_div_match  donor_related  melphalan_dose  \\\n",
       "0                 1              0              1               1   \n",
       "1                 1              1              2               1   \n",
       "2                 1              1              2               1   \n",
       "3                 2              1              1               1   \n",
       "4                 1              1              2               2   \n",
       "...             ...            ...            ...             ...   \n",
       "28795             0              4              0               1   \n",
       "28796             1              2              2               1   \n",
       "28797             0              2              1               1   \n",
       "28798             1              1              2               2   \n",
       "28799             1              1              2               2   \n",
       "\n",
       "       hla_low_res_8  cardiac  hla_match_drb1_high  pulm_moderate  \\\n",
       "0                8.0        1                  2.0              1   \n",
       "1                8.0        1                  2.0              2   \n",
       "2                8.0        1                  2.0              1   \n",
       "3                8.0        1                  2.0              1   \n",
       "4                8.0        1                  2.0              1   \n",
       "...              ...      ...                  ...            ...   \n",
       "28795            8.0        0                  2.0              1   \n",
       "28796            6.0        2                  1.0              2   \n",
       "28797            8.0        0                  2.0              1   \n",
       "28798            4.0        1                  1.0              1   \n",
       "28799            8.0        1                  2.0              2   \n",
       "\n",
       "       hla_low_res_10  efs  efs_time         y  \n",
       "0                10.0  0.0    42.356  0.458687  \n",
       "1                10.0  1.0     4.672  0.847759  \n",
       "2                10.0  0.0    19.793  0.462424  \n",
       "3                10.0  0.0   102.349  0.456661  \n",
       "4                10.0  0.0    16.223  0.464674  \n",
       "...               ...  ...       ...       ...  \n",
       "28795            10.0  0.0    18.633  0.462846  \n",
       "28796             8.0  1.0     4.892  0.825494  \n",
       "28797            10.0  0.0    23.157  0.461142  \n",
       "28798             5.0  0.0    52.351  0.458404  \n",
       "28799            10.0  0.0    25.158  0.460616  \n",
       "\n",
       "[28800 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = train.select_dtypes(include=[\"object\"]).columns\n",
    "cat_features_2 = [col for col in train.columns if col not in [\"donor_age\" , \"comorbidity_score\" , \"age_at_hct\" , \"year_hct\"]]\n",
    "com = pd.concat([train , test])\n",
    "for cat_col in cat_features :\n",
    "    com[cat_col] , _ = com[cat_col].factorize()\n",
    "    com[cat_col]-= com[cat_col].min()\n",
    "\n",
    "\n",
    "def tr(X):\n",
    "    new = X.copy()\n",
    "    cat_new = [x for x in cat_features if x in X.columns]\n",
    "    new[cat_new] = new[cat_new].astype(\"category\")\n",
    "    return new\n",
    "\n",
    "\n",
    "train_encoded = com.iloc[:len(train) , :]\n",
    "\n",
    "test_encoded = com.iloc[len(train): , :]\n",
    "\n",
    "train_encoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a92db83a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.952472Z",
     "iopub.status.busy": "2025-01-12T20:31:56.952051Z",
     "iopub.status.idle": "2025-01-12T20:31:56.956916Z",
     "shell.execute_reply": "2025-01-12T20:31:56.956050Z"
    },
    "papermill": {
     "duration": 0.016616,
     "end_time": "2025-01-12T20:31:56.958416",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.941800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tr(X):\n",
    "    new = X.copy()\n",
    "    cat_new = [x for x in cat_features if x in X.columns]\n",
    "    new[cat_new] = new[cat_new].astype(\"category\")\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8857b1de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:56.978428Z",
     "iopub.status.busy": "2025-01-12T20:31:56.978047Z",
     "iopub.status.idle": "2025-01-12T20:31:56.989140Z",
     "shell.execute_reply": "2025-01-12T20:31:56.988125Z"
    },
    "papermill": {
     "duration": 0.022745,
     "end_time": "2025-01-12T20:31:56.990829",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.968084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ranking_loss(y_true, preds, a):\n",
    "    sign = np.sign(rankdata(preds)-rankdata(y_true))\n",
    "    term1 = sign * (3 * np.cos(preds) * (sign * (-np.sin(y_true) + np.sin(preds))) ** (a - 1))\n",
    "    term2 = sign * (3 * np.sin(preds) * (sign * (-np.cos(y_true) + np.cos(preds))) ** (a - 1))\n",
    "    return term1 - term2\n",
    "    \n",
    "def get_hess(y_true , preds , a , sign = 1):\n",
    "    if sign == -1:\n",
    "        sign_neg = (\n",
    "                3 * (a - 1) * (-np.cos(preds) + np.cos(y_true))**(a - 1) * np.sin(preds)**2 / (-np.cos(preds) + np.cos(y_true)) +\n",
    "                3 * (a - 1) * (-np.sin(preds) + np.sin(y_true))**(a - 1) * np.cos(preds)**2 / (-np.sin(preds) + np.sin(y_true)) +\n",
    "                3 * (-np.sin(preds) + np.sin(y_true))**(a - 1) * np.sin(preds) +\n",
    "                3 * (-np.cos(preds) + np.cos(y_true))**(a - 1) * np.cos(preds)\n",
    "            )\n",
    "        return sign_neg\n",
    "    elif sign==1:\n",
    "\n",
    "        sign_positive = (\n",
    "                3 * (a - 1) * (np.cos(preds) - np.cos(y_true))**(a - 1) * np.sin(preds)**2 / (np.cos(preds) - np.cos(y_true)) +\n",
    "                3 * (a - 1) * (np.sin(preds) - np.sin(y_true))**(a - 1) * np.cos(preds)**2 / (np.sin(preds) - np.sin(y_true)) -\n",
    "                3 * (np.sin(preds) - np.sin(y_true))**(a - 1) * np.sin(preds) -\n",
    "                3 * (np.cos(preds) - np.cos(y_true))**(a - 1) * np.cos(preds)\n",
    "            )\n",
    "        return sign_positive\n",
    "    else :\n",
    "        return None\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def ranking_sine_loss(y_true , preds , a = 2.5):\n",
    "     # print(\"loss_switched\" , end=\"\\r\")\n",
    "     sign = np.sign(rankdata(preds) - rankdata(y_true))\n",
    "     grad = ranking_loss(y_true , preds , a)\n",
    "     hess = np.where(\n",
    "         sign==1,\n",
    "         get_hess(y_true , preds , 2 , sign = 1),\n",
    "         get_hess(y_true , preds , 2 , sign = -1)\n",
    "     )\n",
    "     return grad , hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e54028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.010184Z",
     "iopub.status.busy": "2025-01-12T20:31:57.009820Z",
     "iopub.status.idle": "2025-01-12T20:31:57.015692Z",
     "shell.execute_reply": "2025-01-12T20:31:57.014704Z"
    },
    "papermill": {
     "duration": 0.017339,
     "end_time": "2025-01-12T20:31:57.017205",
     "exception": false,
     "start_time": "2025-01-12T20:31:56.999866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_cols(data = None ,col1 =None , col2=None):\n",
    "    combined_cols = data[col1].astype(str) + \"_\" + data[col2].astype(str)\n",
    "    return combined_cols.astype(\"category\")\n",
    "\n",
    "def add_interactions(data :pd.DataFrame = None , cols :list[tuple]=None)->pd.DataFrame:\n",
    "    data = data.copy()\n",
    "    new_data = {f\"{col1}_{col2}\" :combine_cols(data = data , col1 =col1 , col2 = col2)\n",
    "                    for col1 , col2 in cols}\n",
    "    df_new = pd.concat([data , pd.DataFrame(new_data)] , axis = 1)\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ffdaff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.036752Z",
     "iopub.status.busy": "2025-01-12T20:31:57.036412Z",
     "iopub.status.idle": "2025-01-12T20:31:57.040899Z",
     "shell.execute_reply": "2025-01-12T20:31:57.039771Z"
    },
    "papermill": {
     "duration": 0.015978,
     "end_time": "2025-01-12T20:31:57.042601",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.026623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_col = [\"hla_match_c_high\" , \"hla_high_res_8\" , \"hla_low_res_6\" , \"hla_high_res_6\"]\n",
    "cols_int = [(\"sex_match\" , \"race_group\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee56afcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.062026Z",
     "iopub.status.busy": "2025-01-12T20:31:57.061692Z",
     "iopub.status.idle": "2025-01-12T20:31:57.110795Z",
     "shell.execute_reply": "2025-01-12T20:31:57.109615Z"
    },
    "papermill": {
     "duration": 0.06093,
     "end_time": "2025-01-12T20:31:57.112691",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.051761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_encoded_f = train_encoded.copy()\n",
    "test_encoded_f = test_encoded.copy()\n",
    "train_encoded_f[\"isnull\"] = train_encoded_f.isnull().sum(axis = 1)\n",
    "train_encoded_f[\"feat\"]=train_encoded_f[num_col].mean(axis =1)\n",
    "\n",
    "\n",
    "test_encoded_f[\"isnull\"] = test_encoded_f.isnull().sum(axis = 1)\n",
    "test_encoded_f[\"feat\"]=test_encoded_f[num_col].mean(axis =1)\n",
    "# train_encoded_f = add_interactions(data = train_encoded_f , cols =cols_int)\n",
    "# train_encoded_f = train_encoded_f.drop([\"melphalan_dose\" , \"rheum_issue\" \n",
    "#                                         , \"renal_issue\" , \"obesity\" ] , axis = 1)\n",
    "# train_encoded_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be8914f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.132687Z",
     "iopub.status.busy": "2025-01-12T20:31:57.132319Z",
     "iopub.status.idle": "2025-01-12T20:31:57.289328Z",
     "shell.execute_reply": "2025-01-12T20:31:57.288316Z"
    },
    "papermill": {
     "duration": 0.168747,
     "end_time": "2025-01-12T20:31:57.291033",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.122286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>vent_hist</th>\n",
       "      <th>renal_issue</th>\n",
       "      <th>pulm_severe</th>\n",
       "      <th>prim_disease_hct</th>\n",
       "      <th>hla_high_res_6</th>\n",
       "      <th>cmv_status</th>\n",
       "      <th>hla_high_res_10</th>\n",
       "      <th>hla_match_dqb1_high</th>\n",
       "      <th>tce_imm_match</th>\n",
       "      <th>hla_nmdp_6</th>\n",
       "      <th>hla_match_c_low</th>\n",
       "      <th>rituximab</th>\n",
       "      <th>hla_match_drb1_low</th>\n",
       "      <th>hla_match_dqb1_low</th>\n",
       "      <th>prod_type</th>\n",
       "      <th>cyto_score_detail</th>\n",
       "      <th>conditioning_intensity</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>year_hct</th>\n",
       "      <th>obesity</th>\n",
       "      <th>mrd_hct</th>\n",
       "      <th>in_vivo_tcd</th>\n",
       "      <th>tce_match</th>\n",
       "      <th>hla_match_a_high</th>\n",
       "      <th>hepatic_severe</th>\n",
       "      <th>donor_age</th>\n",
       "      <th>prior_tumor</th>\n",
       "      <th>hla_match_b_low</th>\n",
       "      <th>peptic_ulcer</th>\n",
       "      <th>age_at_hct</th>\n",
       "      <th>hla_match_a_low</th>\n",
       "      <th>gvhd_proph</th>\n",
       "      <th>rheum_issue</th>\n",
       "      <th>sex_match</th>\n",
       "      <th>hla_match_b_high</th>\n",
       "      <th>race_group</th>\n",
       "      <th>comorbidity_score</th>\n",
       "      <th>karnofsky_score</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>isnull</th>\n",
       "      <th>feat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18932</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>70.867</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21280</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.287</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52.305</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27880</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.994</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.212</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15692</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.309</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25416</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.013</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.614</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.247</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.476</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.550</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19463</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>63.472</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57.731</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>63.437</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>58.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dri_score psych_disturb cyto_score diabetes  hla_match_c_high  \\\n",
       "18932         3             1          2        1               2.0   \n",
       "21280         2             1          1        1               2.0   \n",
       "27880         3             1          1        2               2.0   \n",
       "15692         1             1          2        2               1.0   \n",
       "25416         3             1          2        0               2.0   \n",
       "...         ...           ...        ...      ...               ...   \n",
       "2727          5             1          0        1               1.0   \n",
       "9986          6             1          0        1               2.0   \n",
       "1604          7             1          0        1               2.0   \n",
       "19463         2             3          2        1               2.0   \n",
       "4564          8             3          2        1               NaN   \n",
       "\n",
       "       hla_high_res_8 tbi_status arrhythmia  hla_low_res_6 graft_type  \\\n",
       "18932             7.0          0          3            5.0          0   \n",
       "21280             8.0          0          1            6.0          1   \n",
       "27880             7.0          0          1            5.0          0   \n",
       "15692             4.0          0          1            4.0          1   \n",
       "25416             8.0          0          0            6.0          1   \n",
       "...               ...        ...        ...            ...        ...   \n",
       "2727              4.0          2          1            3.0          1   \n",
       "9986              8.0          0          1            6.0          1   \n",
       "1604              8.0          0          1            6.0          0   \n",
       "19463             8.0          0          1            6.0          1   \n",
       "4564              NaN          0          1            NaN          1   \n",
       "\n",
       "      vent_hist renal_issue pulm_severe prim_disease_hct  hla_high_res_6  \\\n",
       "18932         1           1           1                9             5.0   \n",
       "21280         1           1           0                3             6.0   \n",
       "27880         2           1           1                1             5.0   \n",
       "15692         1           1           1               11             3.0   \n",
       "25416         1           0           0               11             6.0   \n",
       "...         ...         ...         ...              ...             ...   \n",
       "2727          1           1           2                3             3.0   \n",
       "9986          1           1           1                0             6.0   \n",
       "1604          1           1           1                0             6.0   \n",
       "19463         1           1           1                1             6.0   \n",
       "4564          1           1           1               11             NaN   \n",
       "\n",
       "      cmv_status  hla_high_res_10  hla_match_dqb1_high tce_imm_match  \\\n",
       "18932          1              9.0                  2.0             1   \n",
       "21280          1             10.0                  2.0             0   \n",
       "27880          2              9.0                  2.0             1   \n",
       "15692          1              5.0                  1.0             1   \n",
       "25416          1             10.0                  2.0             1   \n",
       "...          ...              ...                  ...           ...   \n",
       "2727           1              5.0                  1.0             1   \n",
       "9986           1             10.0                  2.0             7   \n",
       "1604           4             10.0                  2.0             1   \n",
       "19463          4             10.0                  2.0             4   \n",
       "4564           1              NaN                  NaN             0   \n",
       "\n",
       "       hla_nmdp_6  hla_match_c_low rituximab  hla_match_drb1_low  \\\n",
       "18932         6.0              2.0         1                 1.0   \n",
       "21280         6.0              2.0         1                 2.0   \n",
       "27880         4.0              2.0         1                 1.0   \n",
       "15692         5.0              2.0         1                 1.0   \n",
       "25416         6.0              2.0         1                 2.0   \n",
       "...           ...              ...       ...                 ...   \n",
       "2727          3.0              1.0         1                 1.0   \n",
       "9986          6.0              2.0         1                 2.0   \n",
       "1604          6.0              2.0         1                 2.0   \n",
       "19463         6.0              2.0         1                 2.0   \n",
       "4564          NaN              NaN         1                 NaN   \n",
       "\n",
       "       hla_match_dqb1_low prod_type cyto_score_detail conditioning_intensity  \\\n",
       "18932                 2.0         1                 3                      2   \n",
       "21280                 2.0         1                 0                      5   \n",
       "27880                 2.0         0                 1                      2   \n",
       "15692                 2.0         1                 3                      1   \n",
       "25416                 2.0         1                 3                      1   \n",
       "...                   ...       ...               ...                    ...   \n",
       "2727                  2.0         1                 0                      3   \n",
       "9986                  2.0         1                 0                      0   \n",
       "1604                  2.0         0                 0                      0   \n",
       "19463                 2.0         1                 3                      1   \n",
       "4564                  NaN         1                 3                      1   \n",
       "\n",
       "      ethnicity  year_hct obesity mrd_hct in_vivo_tcd tce_match  \\\n",
       "18932         1      2012       1       2           2         0   \n",
       "21280         1      2017       1       0           2         0   \n",
       "27880         1      2016       1       2           2         0   \n",
       "15692         1      2018       2       2           2         0   \n",
       "25416         1      2016       1       0           1         0   \n",
       "...         ...       ...     ...     ...         ...       ...   \n",
       "2727          1      2018       1       0           2         0   \n",
       "9986          1      2016       1       0           1         0   \n",
       "1604          1      2018       1       0           1         0   \n",
       "19463         1      2017       1       2           2         0   \n",
       "4564          1      2017       2       0           2         0   \n",
       "\n",
       "       hla_match_a_high hepatic_severe  donor_age prior_tumor  \\\n",
       "18932               2.0              1     70.867           1   \n",
       "21280               2.0              0     23.287           1   \n",
       "27880               2.0              1     30.994           1   \n",
       "15692               1.0              1     50.309           2   \n",
       "25416               2.0              0     57.013           1   \n",
       "...                 ...            ...        ...         ...   \n",
       "2727                1.0              1     24.614           1   \n",
       "9986                2.0              1     57.247           1   \n",
       "1604                2.0              2        NaN           1   \n",
       "19463               2.0              1     63.472           1   \n",
       "4564                NaN              1     63.437           1   \n",
       "\n",
       "       hla_match_b_low peptic_ulcer  age_at_hct  hla_match_a_low gvhd_proph  \\\n",
       "18932              2.0            1      50.961              2.0          9   \n",
       "21280              2.0            1      52.305              2.0          4   \n",
       "27880              2.0            1      63.212              2.0          3   \n",
       "15692              2.0            1      53.097              1.0          9   \n",
       "25416              2.0            0      58.100              2.0          8   \n",
       "...                ...          ...         ...              ...        ...   \n",
       "2727               1.0            1      32.526              1.0          3   \n",
       "9986               2.0            1      12.476              2.0          1   \n",
       "1604               2.0            1       6.550              2.0          1   \n",
       "19463              2.0            1      57.731              2.0          4   \n",
       "4564               NaN            1      58.326              NaN          8   \n",
       "\n",
       "      rheum_issue sex_match  hla_match_b_high race_group  comorbidity_score  \\\n",
       "18932           1         3               2.0          3                4.0   \n",
       "21280           1         3               2.0          5                0.0   \n",
       "27880           1         2               2.0          4                6.0   \n",
       "15692           1         4               1.0          1                5.0   \n",
       "25416           0         1               2.0          0                2.0   \n",
       "...           ...       ...               ...        ...                ...   \n",
       "2727            1         2               1.0          0                4.0   \n",
       "9986            1         1               2.0          0                1.0   \n",
       "1604            2         4               2.0          1                0.0   \n",
       "19463           1         4               2.0          1                2.0   \n",
       "4564            1         4               NaN          1                0.0   \n",
       "\n",
       "       karnofsky_score hepatic_mild tce_div_match donor_related  \\\n",
       "18932             90.0            1             1             2   \n",
       "21280              NaN            1             0             1   \n",
       "27880             70.0            2             1             2   \n",
       "15692             40.0            1             1             2   \n",
       "25416             60.0            1             1             2   \n",
       "...                ...          ...           ...           ...   \n",
       "2727              90.0            1             1             2   \n",
       "9986              80.0            1             0             2   \n",
       "1604              90.0            2             1             2   \n",
       "19463             90.0            1             2             2   \n",
       "4564             100.0            1             0             2   \n",
       "\n",
       "      melphalan_dose  hla_low_res_8 cardiac  hla_match_drb1_high  \\\n",
       "18932              1            7.0       2                  1.0   \n",
       "21280              0            8.0       1                  2.0   \n",
       "27880              1            7.0       2                  1.0   \n",
       "15692              2            6.0       1                  1.0   \n",
       "25416              1            8.0       0                  2.0   \n",
       "...              ...            ...     ...                  ...   \n",
       "2727               1            4.0       1                  1.0   \n",
       "9986               2            8.0       1                  2.0   \n",
       "1604               1            8.0       1                  2.0   \n",
       "19463              1            8.0       1                  2.0   \n",
       "4564               1            NaN       1                  NaN   \n",
       "\n",
       "      pulm_moderate  hla_low_res_10  isnull  feat  \n",
       "18932             2             9.0       0  4.75  \n",
       "21280             1            10.0       1  5.50  \n",
       "27880             2             9.0       0  4.75  \n",
       "15692             1             8.0       0  3.00  \n",
       "25416             0            10.0       0  5.50  \n",
       "...             ...             ...     ...   ...  \n",
       "2727              1             6.0       0  2.75  \n",
       "9986              1            10.0       0  5.50  \n",
       "1604              2            10.0       1  5.50  \n",
       "19463             1            10.0       0  5.50  \n",
       "4564              2             NaN      17   NaN  \n",
       "\n",
       "[5760 rows x 59 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [\"ID\" , \"efs_time\" , \"efs\" , \"y\"]\n",
    "\n",
    "X = train_encoded_f.drop(columns_to_drop , axis = 1)\n",
    "y = train_encoded_f[\"y\"]\n",
    "\n",
    "train_encoded_f[\"efs_time_2\"] =train_encoded_f[\"efs_time\"].copy()\n",
    "train_encoded_f.loc[train_encoded_f.efs==0 , \"efs_time_2\"]*=-1\n",
    "\n",
    "y_cox = train_encoded_f[\"efs_time_2\"]\n",
    "\n",
    "test_data = test_encoded_f.drop(columns_to_drop , axis = 1)\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(tr(X) , y \n",
    "                                                       , test_size = 0.2 , random_state = 42)\n",
    "\n",
    "train_train , train_test = train_test_split(train ,\n",
    "                                        test_size = 0.2 , random_state = 42)\n",
    "\n",
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45247fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.312741Z",
     "iopub.status.busy": "2025-01-12T20:31:57.312405Z",
     "iopub.status.idle": "2025-01-12T20:31:57.322256Z",
     "shell.execute_reply": "2025-01-12T20:31:57.321363Z"
    },
    "papermill": {
     "duration": 0.022384,
     "end_time": "2025-01-12T20:31:57.323784",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.301400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_metric_(y_true , y_pred , indices = train_test.index):\n",
    "        score = evaluate_(pred = y_pred , indices =indices )\n",
    "        return 1 - score \n",
    "def ranking_sine_loss(y_true , preds , a = 2):\n",
    "     # print(\"loss_switched\" , end=\"\\r\")\n",
    "     sign = np.sign(rankdata(preds) - rankdata(y_true))\n",
    "     grad = ranking_loss(y_true , preds , a)\n",
    "     hess = np.where(\n",
    "         sign==1,\n",
    "         get_hess(y_true , preds , a , sign = 1),\n",
    "         get_hess(y_true , preds , a , sign = -1)\n",
    "     )\n",
    "     return grad , hess\n",
    "\n",
    "def mse_loss(y_true , preds):\n",
    "    grad = 2*(preds - y_true)\n",
    "    hess = np.full_like(y_true , 2)\n",
    "        \n",
    "    return grad , hess\n",
    "\n",
    "def limited_mae_loss(limit = 0.05):\n",
    "    def mae_loss(y_true , preds ):\n",
    "        residual = preds - y_true\n",
    "        grad = np.sign(residual)\n",
    "        hess = np.full_like(y_true , 2)\n",
    "        \n",
    "        grad = np.where(\n",
    "            np.abs(residual)<=limit,\n",
    "            grad,\n",
    "            0\n",
    "        )\n",
    "\n",
    "        hess = np.where(\n",
    "            np.abs(residual)<=limit,\n",
    "            hess,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "        return grad , hess\n",
    "    return mae_loss\n",
    "def mse_limited_wrapper(deviation = 0.05):\n",
    "    def mse_limited(y_true , preds , deviation = deviation):\n",
    "        residual = preds - y_true\n",
    "        grad = preds - y_true\n",
    "        hess = np.ones_like(y_true)\n",
    "    \n",
    "        grad = np.where(\n",
    "            np.abs(y_true-preds)<deviation,\n",
    "            grad,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "        hess = np.where(\n",
    "            np.abs(y_true-preds)<deviation,\n",
    "            hess,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "        \n",
    "    \n",
    "        return grad , hess\n",
    "    return mse_limited\n",
    "\n",
    "\n",
    "\n",
    "def ranking_log_loss(y_true , preds , a  = 1000):\n",
    "    sign = np.sign(y_true - preds) #1 if y_true > preds , -1 if y_true<preds\n",
    "    grad = np.where(\n",
    "        sign==1,\n",
    "        -a/(0.01+a*(-preds+y_true)), #b>x\n",
    "        a/(0.01+a*(preds-y_true)) #x>b\n",
    "    )\n",
    "\n",
    "\n",
    "    hess = np.where(\n",
    "        sign==1,\n",
    "        -(a)**2/(0.01+a*(-preds+y_true))**2, #b>x\n",
    "        -(a)**2/(0.01+a*(preds-y_true))**2 #x>b\n",
    "    )\n",
    "\n",
    "    return grad , hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef2b0fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.345503Z",
     "iopub.status.busy": "2025-01-12T20:31:57.345087Z",
     "iopub.status.idle": "2025-01-12T20:31:57.359053Z",
     "shell.execute_reply": "2025-01-12T20:31:57.357955Z"
    },
    "papermill": {
     "duration": 0.026495,
     "end_time": "2025-01-12T20:31:57.360640",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.334145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from collections import OrderedDict\n",
    "\n",
    "class DynamicLoss:\n",
    "    def __init__(self, switch_epoch , first_loss=mse_loss , second_loss = None , third_loss =None):\n",
    "        self.switch_epoch = switch_epoch  # Epoch to switch loss\n",
    "        self.current_loss = first_loss       # Start with loss_1\n",
    "        self.second_loss = second_loss\n",
    "        self.third_loss = third_loss\n",
    "        self.loss_switched = False\n",
    "    def __call__(self, y_true, preds):\n",
    "        return self.current_loss(y_true, preds)\n",
    "\n",
    "\n",
    "    def switch_loss(self):\n",
    "        if not self.loss_switched:\n",
    "            self.current_loss = self.second_loss if self.second_loss is not None else self.current_loss \n",
    "            self.loss_switched = True\n",
    "        else :\n",
    "            self.current_loss = self.third_loss if self.third_loss is not None else self.second_loss\n",
    "\n",
    "\n",
    "class EpochAwareCallback(xgb.callback.TrainingCallback):\n",
    "    def __init__(self , initial_lr=0.1 , verbose = 100 , dynamic_loss = None , testing_data = None , decay_at = 300 , decay_rate = 0.1 , perform_decay = False):\n",
    "\n",
    "        self.initial_lr = initial_lr\n",
    "        self.verbose = verbose\n",
    "        self.dynamic_loss = dynamic_loss\n",
    "        self.switch_epoch = dynamic_loss.switch_epoch if dynamic_loss is not None else None\n",
    "        self.testing_data = testing_data\n",
    "        self.decay_at = decay_at\n",
    "        self.decay_rate = decay_rate\n",
    "        self.perform_decay = perform_decay\n",
    "        self.eval_log = None\n",
    "\n",
    "    def learning_rate_decay(self , epoch , decay_rate=0.01):\n",
    "        return self.initial_lr* (1.0 / (1.0 + decay_rate * epoch))\n",
    "\n",
    "\n",
    "    \n",
    "    def target_metric_(self , y_true , y_pred , indices = None):\n",
    "        score = evaluate_(pred = y_pred , indices =indices )\n",
    "        return score \n",
    "\n",
    "    def c_index_metric(self ,model , testing_data= None):\n",
    "        dtest = xgb.DMatrix(testing_data , enable_categorical=True)\n",
    "        pred = model.predict(dtest)\n",
    "        \n",
    "        return self.target_metric_( pred, pred , indices = testing_data.index)\n",
    "\n",
    "    def perform_lr_decay(self ,model, epoch):\n",
    "        epoch_to_decay_at = self.decay_at\n",
    "        if epoch > epoch_to_decay_at:\n",
    "            new_learning_rate = self.learning_rate_decay(epoch - epoch_to_decay_at \n",
    "                                                         , decay_rate = self.decay_rate) \n",
    "            if self.switch_epoch == epoch:\n",
    "                new_learning_rate = self.learning_rate_decay(epoch - self.switch_epoch \n",
    "                                             , decay_rate = self.decay_rate) \n",
    "                \n",
    "            model.set_param('learning_rate', new_learning_rate)\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        if not self.verbose==0:\n",
    "            if epoch%self.verbose==0:\n",
    "                \n",
    "                c_index = self.c_index_metric(model ,testing_data =  self.testing_data)\n",
    "                if epoch==0:\n",
    "                    evals_log[\"validation_0\"][\"c_index\"] = [c_index]\n",
    "                    evals_log[\"validation_0\"].move_to_end('c_index', last=False)\n",
    "                else:\n",
    "                    evals_log[\"validation_0\"][\"c_index\"].append(c_index)\n",
    "                    self.eval_log = evals_log[\"validation_0\"][\"c_index\"]\n",
    "                \n",
    "\n",
    "        if self.perform_decay:\n",
    "            self.perform_lr_decay(model , epoch)\n",
    "            \n",
    "\n",
    "        epoch_to_switch_loss_1 = self.switch_epoch[0]\n",
    "        epoch_to_switch_loss_2 = self.switch_epoch[1]\n",
    "        \n",
    "        \n",
    "        if (epoch == epoch_to_switch_loss_1) or (epoch == epoch_to_switch_loss_2) and not self.switch_epoch is None :\n",
    "            # print(\"loss_swiched\")\n",
    "            self.dynamic_loss.switch_loss()\n",
    "            model.set_param('max_depth', 11)\n",
    "            model.set_param('colsample_bytree', .35042075533001182 )#0.4342075533001182  #35042075533001182\n",
    "            # model.set_param('learning_rate', new_learning_rate)\n",
    "\n",
    "        return False\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2634b434",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.382063Z",
     "iopub.status.busy": "2025-01-12T20:31:57.381732Z",
     "iopub.status.idle": "2025-01-12T20:31:57.388127Z",
     "shell.execute_reply": "2025-01-12T20:31:57.387157Z"
    },
    "papermill": {
     "duration": 0.0192,
     "end_time": "2025-01-12T20:31:57.389970",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.370770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ln_cosh_loss(y_true, y_pred):\n",
    "    # Calculate the absolute error\n",
    "    error = np.abs(y_true - y_pred)\n",
    "    \n",
    "    # Calculate the gradient (first derivative of the loss)\n",
    "    grad = np.sign(y_pred - y_true) * np.sinh(error)\n",
    "    \n",
    "    # Calculate the hessian (second derivative of the loss)\n",
    "    hess = np.cosh(error)\n",
    "    \n",
    "    return grad, hess\n",
    "\n",
    "\n",
    "\n",
    "def ln_cosh_loss_wrapper(a = 1 , limit=np.inf):\n",
    "    def ln_cosh_loss_with_a(y_true, y_pred, a=a):\n",
    "        # Calculate the absolute error, scaled by 'a'\n",
    "        error = np.abs(y_true - y_pred)\n",
    "        scaled_error = a * error  # Apply scaling factor\n",
    "    \n",
    "        # Calculate the gradient (first derivative of the loss)\n",
    "        grad = -a * np.sign(y_true - y_pred) * np.sinh(scaled_error)\n",
    "    \n",
    "        # Calculate the hessian (second derivative of the loss)\n",
    "        hess = a**2 * np.cosh(scaled_error)\n",
    "\n",
    "        grad = np.where(\n",
    "            error<=limit,\n",
    "            grad,\n",
    "            0\n",
    "        )\n",
    "\n",
    "\n",
    "        hess = np.where(\n",
    "            error<=limit,\n",
    "            hess,\n",
    "            0\n",
    "        )\n",
    "    \n",
    "        return grad, hess\n",
    "    return ln_cosh_loss_with_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3d97c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.411871Z",
     "iopub.status.busy": "2025-01-12T20:31:57.411496Z",
     "iopub.status.idle": "2025-01-12T20:31:57.419735Z",
     "shell.execute_reply": "2025-01-12T20:31:57.418892Z"
    },
    "papermill": {
     "duration": 0.020789,
     "end_time": "2025-01-12T20:31:57.421184",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.400395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_oof(X , y , params = None):\n",
    "        model_2 = XGBRegressor(\n",
    "        **{'objective': \"reg:squarederrror\",\n",
    "                        'max_depth': 8,#8\n",
    "                        'min_child_weight': 88,\n",
    "                        'gamma': 0.08191438618604895,\n",
    "                        'subsample': 0.709785867220118,\n",
    "                        'colsample_bytree': 0.5342075533001182,#0.5342075533001182\n",
    "                        \"learning_rate\": 0.02,\n",
    "                        \"n_estimators\": 2500,\n",
    "                        'enable_categorical':True,\n",
    "                        'random_state':42}  , eval_metrics = None\n",
    "                        # , early_stopping_rounds=2300\n",
    "        )\n",
    "\n",
    "\n",
    "        n_splits = 10\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        oof_predictions = np.zeros(len(X))  # Assuming X_train is already defined\n",
    "\n",
    "\n",
    "\n",
    "        best_iterations = []\n",
    "        for fold, (train_idx, valid_idx) in tqdm(enumerate(kf.split(tr(X) ,y)) , total=n_splits):\n",
    "            # Split the data\n",
    "            X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "            y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "            model_ =clone(model_2)\n",
    "\n",
    "\n",
    "            dynamic_loss = DynamicLoss(switch_epoch=(1850 , np.inf) \n",
    "                                , first_loss =ln_cosh_loss_wrapper(a=1 ) \n",
    "                                    ,second_loss = ln_cosh_loss_wrapper(a=11 , limit=0.05)\n",
    "                                    )\n",
    "\n",
    "            model_.objective = dynamic_loss\n",
    "\n",
    "\n",
    "            callbacks = [EpochAwareCallback(\n",
    "                                        perform_decay = True\n",
    "                                        ,initial_lr = 0.01\n",
    "                                        , dynamic_loss = dynamic_loss\n",
    "                                        ,verbose = 99\n",
    "                                        , testing_data = X_valid_fold \n",
    "                                        , decay_at = 1850\n",
    "                                        ,decay_rate=0\n",
    "                                        ) ] \n",
    "            model_.callbacks = callbacks\n",
    "\n",
    "            model_.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                eval_set=[(X_valid_fold, y_valid_fold)],  \n",
    "                verbose=0,\n",
    "                # callbacks = callbacks\n",
    "                \n",
    "            )\n",
    "\n",
    "            \n",
    "            oof_preds = model_.predict(X_valid_fold).reshape(-1,)\n",
    "            oof_predictions[valid_idx] = oof_preds\n",
    "        return oof_predictions , evaluate_(pred = oof_predictions  , indices = X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0111e22b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.443095Z",
     "iopub.status.busy": "2025-01-12T20:31:57.442737Z",
     "iopub.status.idle": "2025-01-12T20:31:57.446340Z",
     "shell.execute_reply": "2025-01-12T20:31:57.445478Z"
    },
    "papermill": {
     "duration": 0.01626,
     "end_time": "2025-01-12T20:31:57.447890",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.431630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# columns = X.columns\n",
    "# columns_to_drop =  ['hla_low_res_8', 'hla_high_res_8', 'hla_high_res_8', 'hla_high_res_6', 'race_group', 'tce_imm_match', 'peptic_ulcer', 'hepatic_severe'] \n",
    "# X_exp = tr(X.copy()).drop(columns_to_drop , axis = 1)\n",
    "# oof , eval_ = get_oof(X_exp , y)\n",
    "# eval_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53fe2b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.469369Z",
     "iopub.status.busy": "2025-01-12T20:31:57.468985Z",
     "iopub.status.idle": "2025-01-12T20:31:57.472865Z",
     "shell.execute_reply": "2025-01-12T20:31:57.472092Z"
    },
    "papermill": {
     "duration": 0.016155,
     "end_time": "2025-01-12T20:31:57.474313",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.458158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade xgboost==2.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93a348aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:31:57.495759Z",
     "iopub.status.busy": "2025-01-12T20:31:57.495414Z",
     "iopub.status.idle": "2025-01-12T20:32:25.320562Z",
     "shell.execute_reply": "2025-01-12T20:32:25.319430Z"
    },
    "papermill": {
     "duration": 27.837939,
     "end_time": "2025-01-12T20:32:25.322393",
     "exception": false,
     "start_time": "2025-01-12T20:31:57.484454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [20:31:57] WARNING: /workspace/src/context.cc:44: No visible GPU is found, setting device to CPU.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.37475598, 0.7740134 , 0.4050136 ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_loss = DynamicLoss(switch_epoch=(1850 , np.inf) \n",
    "                    , first_loss =ln_cosh_loss_wrapper(a=1 ) \n",
    "                        ,second_loss = ln_cosh_loss_wrapper(a=11 , limit=0.05)\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [EpochAwareCallback(\n",
    "                            perform_decay = True\n",
    "                            ,initial_lr = 0.01\n",
    "                            , dynamic_loss = dynamic_loss\n",
    "                            ,verbose = 0\n",
    "                            , testing_data = None \n",
    "                            , decay_at = 1850\n",
    "                            ,decay_rate=0\n",
    "                            ) ] \n",
    "\n",
    "model_xgb = XGBRegressor(\n",
    "        **{'objective': dynamic_loss,\n",
    "                        'max_depth': 8,#8\n",
    "                        'min_child_weight': 88,\n",
    "                        'gamma': 0.08191438618604895,\n",
    "                        'subsample': 0.709785867220118,\n",
    "                        'colsample_bytree': 0.5342075533001182,#0.5342075533001182\n",
    "                        \"learning_rate\": 0.02,\n",
    "                        \"n_estimators\": 2500,\n",
    "                        'enable_categorical':True,\n",
    "                        'random_state':42} , device = \"cuda\" , eval_metrics = None , callbacks = callbacks\n",
    "                        # , early_stopping_rounds=2300\n",
    "        )\n",
    "columns_to_drop =  ['hla_low_res_8', 'hla_high_res_8', 'hla_high_res_8', 'hla_high_res_6', 'race_group', 'tce_imm_match', 'peptic_ulcer', 'hepatic_severe'] \n",
    "X_exp = tr(X.copy()).drop(columns_to_drop , axis = 1)\n",
    "test_exp = (tr(test_data.copy())).drop(columns_to_drop , axis = 1)\n",
    "\n",
    "model_xgb.fit(\n",
    "    X_exp , y , verbose = 0\n",
    ")\n",
    "\n",
    "pred_xgb = model_xgb.predict(test_exp)\n",
    "pred_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd605e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T20:32:25.346510Z",
     "iopub.status.busy": "2025-01-12T20:32:25.346146Z",
     "iopub.status.idle": "2025-01-12T20:32:25.353427Z",
     "shell.execute_reply": "2025-01-12T20:32:25.352520Z"
    },
    "papermill": {
     "duration": 0.019942,
     "end_time": "2025-01-12T20:32:25.355085",
     "exception": false,
     "start_time": "2025-01-12T20:32:25.335143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\":test[\"ID\"],\n",
    "        \"prediction\":pred_xgb\n",
    "    }\n",
    ")\n",
    "submission.to_csv(\"submission.csv\" , index = False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10381525,
     "sourceId": 70942,
     "sourceType": "competition"
    },
    {
     "datasetId": 6470266,
     "sourceId": 10452433,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 211322530,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.105483,
   "end_time": "2025-01-12T20:32:26.487311",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-12T20:31:23.381828",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
